<?xml version="1.0" encoding="UTF-8"?>
<p>The development, identification, and dissemination of evidence-based intervention and assessment strategies have been a dominant theme within education for more than a decade (</p>
<p>Despite the importance of systematic reviews for understanding and addressing an array of complex issues for students with EBD, field-specific guidance for researchers or practitioners on this research methodology is currently unavailable. The purpose of this article, therefore, is to follow the lead of previous efforts in the field to establish guidelines and provide an overview of common quality indicators for conducting systematic reviews (</p>
Defining Systematic Reviews<p>A systematic review is the attempt to systematically collate all empirical evidence that meets a set of specific eligibility criteria with the purpose of answering a particular research question (</p>
Guidelines for Systematic Reviews<p>Part of the motivation for the current article is to provide researchers and research consumers with a set of guidelines to use when conducting and reviewing systematic reviews. These efforts are similar to the development of indicators for primary research proposed by our esteemed colleagues in special education more than a decade ago (</p>
Quality Indicators for Systematic Reviews<p>In the following sections, we provide an overview of the quality indicators for conducting systematic reviews. Each criterion and its operational definition are presented in </p>
Table 1.<p>Methodological Quality Indicators for Conducting Systematic Reviews.</p>

Methodological DomainQuality indicatorResearch question?Research question formulationThe research question communicates the objectives and provides boundaries for making decisions about which studies to include in the systematic review.Eligibility criteria?Variable characteristicsOperational characteristics of the variables that will be the focus of the review are described with examples of key variables such as the interventions, assessments, programs, practices, or policies of interest.?Participant informationKey participant information is reported including any disability, demographic, and/or functional characteristics that define the student population.?Research designThe research designs eligible for the review are identified with key methods operationalized if necessary.?Time periodThe time period in which the research had to be published to be eligible was identified.Search procedures?Databases identifiedThe electronic reference databases searched were referenced directly.?Registries identifiedThe prospective research registries searched were referenced directly.?Unpublished sourcesThe authors reported whether unpublished studies were included in the search.?Keywords identifiedKeywords used to search reference databases and registries were explicitly identified.?Search dateThe date on which the final search was conducted was reported.?Hand search conductedThe authors reported whether journals were hand searched and, if so, which journals.?Citation lists reviewThe authors reported whether citation lists of included studies were reviewed and, if so, which studies.?Subject matter expert reviewThe authors reported whether individuals with expertise on the subject matter of the review examined the citation list to assist with identifying additional, relevant studies.?Review articles consultedThe authors reported whether pertinent review articles were reviewed for citations.?Authors contactedThe authors reported whether authors were contacted to see if other reports were available.?Language specificationThe authors specified the languages of eligible reports and if there were any limitations imposed on the language of the report.?Titles and abstracts reviewedThe authors reported whether titles and abstracts were used to determine eligibility in the study.?Searcher qualificationThe authors reported the qualifications for those reviewing studies for eligibility.?Search agreementThe authors reported agreement across those reviewing for study eligibility.Retrieval procedures?Total citations returnThe authors reported the number of studies identified through the initial data-based search (i.e., total returns from search).?Total screened outThe authors reported the number of studies excluded during the initial database search (i.e., how many relevant studies were there to retrieve from the initial number of citations).?Total retrievedThe authors reported the number of studies identified as potentially eligible that were successfully retrieved for full review.?Total excludedThe authors reported the number of studies that were excluded from those after the retrieval process due to ineligibility.Systematic screening?Reasons studies excludedThe authors reported the reasons excluded studies were deemed ineligible.?Total studies included in reviewThe authors reported the total number of studies that met eligibility criteria and were subsequently included in the review.?Coder training and expertiseThe authors reported the training and expertise of those charged with conducting the screening process.?Reliability reportedThe authors reported the reliability or interobserver agreement statistics used to evaluate the consistency of the screening process.?Disagreement resolution methodThe authors reported the method used to resolve any disagreements among screeners.Coding scheme procedures?Coder expertiseThe authors reported the expertise of individuals charged with coding studies.?Coder trainingThe authors reported methods for training individuals charged with coding studies.?Proportion double codedThe authors reported the number and proportion of studies that were coded by more than one independent observer.?Reliability reportedThe authors reported the reliability or interobserver agreement statistics used to evaluate the consistency of the coding.?Disagreements resolution methodThe authors reported the procedures used to resolve disagreements among coders.?Response categories reportedThe authors reported the response categories available for coders to select from.?Missing information processThe authors reported the procedures used to address issues for missing information within research studies, such as checking with authors on missing information.Coding scheme content?Participants characteristicsThe authors collected data pertaining to participants.?Key variable featuresThe authors collected data pertaining to variables under study.?Methodological qualityThe authors collected data pertaining to study quality.Data analysis plan?Data analysis plan providedThe authors provide a data analysis plan.?Coding scheme aggregation specifiedThe data analysis plan includes the method used to descriptively aggregate the data from the coding scheme.?Results method describedThe data analysis plan includes the method used to synthesize the results reported across studies.Research Question<p>As with all types of research, a rigorous systematic review begins with the articulation of the research question that communicates the primary objectives of the review (</p>
Eligibility Criteria<p>Following the development of a research question that provides readers with the critical details and goals of the review, it is necessary to develop a set of criteria that clearly defines the population of studies from which the research team will ultimately sample (</p>
<p>The specific details of what should be included in the eligibility criteria will naturally depend on the purpose of the review. However, most systematic reviews should address information such as (a) the demographic, emotional, behavioral, and academic information that distinguishes the student population of interest; (b) the contexts and settings in which the research has taken place; (c) the pertinent constructs and outcomes and whether there are any restrictions on how these were measured; and (d) the research designs or other methodological characteristics considered when identifying studies (Davies, 2000). Providing detailed inclusion criteria for the particular sample characteristics of interest can be particularly important given the range and complexity of the emotional and behavioral challenges experienced by students with EBD (e.g., </p>
Search Procedures<p>Once the eligibility criteria have been established, the systematic review process moves away from conceptual development toward implementation. The purpose of the search is to identify the universe of eligible studies that meet the eligibility criteria. It is important to note that the strength of the review largely depends on the extent to which all the relevant studies are successfully identified and subsequently retrieved. Each individual study that is included in the review contributes new information either by providing additional support or contrary evidence to the results of the other studies (</p>
<p>Providing a description of the procedures taken to identify studies enhances the transparency of the process for readers and represents an important aspect of systematic reviews. In addition to these procedural steps, a number of additional reporting standards address the extent to which the pool of studies is reflective of the universe of possible studies on the topic. For instance, reporting the qualifications of those individuals conducting the search is important for determining whether there was sufficient expertise and experience, indicating whether there were language barriers that precluded the identification and subsequent review of studies in languages other than English can be an important limitation in many systematic reviews, and providing the date of the final search allows consumers to determine whether the current review is up-to-date or whether additional research might have been published on the topic. Because the intentional or unintentional exclusion of relevant studies raises the possibility that the review findings are not representative of the broader population of research findings, the reporting of these steps is essential to drawing valid and transparent conclusions.</p>
Retrieval Procedures<p>In addition to well-described search procedures, it is also important to provide a transparent and replicable description of the retrieval process (</p>
Coding Scheme Development and Implementation<p>The research questions in a systematic review are often addressed—in full or in part—through the development of a coding scheme. These coding schemes are used to collect descriptive information from the studies that can then be used to characterize the samples, outcome, and other key variables of interest (</p>
Methodological quality<p>Methodological quality refers broadly to the degree to which the research design procedures generate valid results (</p>
Describing participants and settings<p>The evaluation of study quality is important for establishing confidence in the research results; however, even the results of the best designed studies require consideration of the individuals and contexts to which the results can generalize (</p>
Describing the variables under study<p>Systematic reviews are compelling because they organize information across several sources to draw conclusions that are more generalizable than those from a single study. This includes the variability inherent across research participants and contexts included in different studies as well as the variables and phenomena being investigated. As a result, those engaged in conducting systematic reviews should aim to describe the patterns in the outcomes and other key variables used across studies, including important moderator variables. Examples of important moderator variables for systematic reviews of interventions include fidelity of intervention implementation; duration, frequency, and intensity of intervention; and intervention cost (</p>
Data Analysis Plan<p>The goal of a plan for data analysis is to synthesize the results from the review; synthesis is the process of integrating findings from the studies to answer the research question (</p>
<p>The systematic review quality indicators described in the preceding paragraphs represent widely regarded reporting standards (e.g., </p>
<p> To what extent have systematic reviews published in </p>
<p> Are there areas of particular strength and areas in need of more attention?</p>
<p>In the following sections, we describe the procedures used to address these questions.</p>
MethodStudy Identification Procedures<p>The purpose of the current review was to identify systematic reviews and meta-analyses of research published in </p>
Inclusion Criteria<p>The inclusion criteria used to select research reports for the present review were based on (a) the journal of publication and (b) the methodological procedures used within the studies. Broadly, studies were included if systematic review procedures were employed to address the research question. More specifically, systematic reviews were differentiated from other research approaches and less structured reviews if (a) the stated purpose of the research was to review extant literature and (b) there was a formal method section included in the article that described the process for selecting, searching, locating, and analyzing previously existing research studies. Regarding this latter criteria, literature reviews that were developed using narrative rather than systematic procedures were excluded from the present review. Moreover, there were no qualifications placed on the type of research that was included in the original review and, therefore, could include randomized or quasi-experimental, single-case, qualitative, and other research methods. Moreover, the search was restricted to systematic reviews and meta-analyses published between 2005 and 2016 to align with the publication of the Council for Exceptional Children (CEC) methodological quality indicators, which are widely viewed as a watershed development in the field, raising the standards for research (</p>
Study Coding Procedures<p>We coded the identified set of systematic reviews and meta-analyses on 41 items or quality indicators in seven methodological domains drawn from established guidelines for the conduct of systematic reviews and meta-analyses from the </p>
Coder Training and Agreement<p>Two research assistants who had varying levels of expertise and experience with research methods conducted coding. The lead coder was a doctoral student in special education who had taken courses in research design and statistics and had experience in the conduct of previous systematic reviews. The secondary coder was also a special education doctoral student with no previous experience with systematic review procedures. Prior to initiating study coding, the research assistants underwent training that consisted of the following procedures: (a) an introduction to the study and the coding protocol presented by the lead authors; (b) practice coding a subset of reviews and meta-analyses that would have been eligible for the study, except for their publication year (i.e., publication year prior to 2005); and (c) computing agreement statistics for the reviews used for coding practice until there was at least 90% agreement across coders for all codes. Coders were then given studies to code independently, with the lead coder assigned to review all of the eligible studies and the secondary coder assigned a random subset of 30% of the studies to establish interrater agreement. Interrater agreement was computed using a percentage agreement formula in which total agreements for each code were divided by the total agreements plus disagreements. Mean percentages across coders for each methodological domain are presented in </p>
Table 2.<p>Interobserver agreement for each methodological domain sampled in the coding scheme.</p>

Methodological domainTotal agreedTotal possibleInterobserver agreement (%)Research question77100Eligibility criteria272993Search procedures9110190Retrieval procedures242983Systematic screening333692Coding scheme procedures434791Coding scheme content212295Data analysis plan212295Total26729391<p> Interobserver agreement indices were computed based on independent coding of 30% of the studies which were randomly sampled; coder discrepancies were resolved through developing a consensus between coders.</p>
Data Analysis Plan<p>To examine the extent to which systematic reviews and meta-analyses published in </p>
ResultsQuality Indicator ApplicationSearch procedures<p>The search procedure items provided an overview of the extent to which the included reviews were consistent with recommended strategies and practices for identifying relevant studies on the review topic. Results for each item are graphically depicted in </p>
Figure 1.<p>Percentage of systematic review quality indicators marked as present and not for the inclusion and exclusion criteria, screening studies, retrieval procedures, and coding scheme domains.</p>

Inclusion and exclusion criteria<p>The inclusion and exclusion criteria domain provided an overview of the extent to which the included reviews provided information necessary to clearly determine the population of studies that would be eligible for the review. Results for each item included in the domain are graphically presented in the upper left-hand panel of </p>
Retrieval procedures<p>These criteria evaluated reporting of the process used to narrow the initial pool of potentially eligible studies to those included in the review. Results for each item included in the domain are graphically presented in the lower left-hand panel of </p>
Screening studies<p>The process for screening studies domain provided an assessment of the extent to which the included reviews adhered to recommended practices for reporting on the screening process. Results for each item included in the domain are graphically presented in the upper right-hand panel of </p>
Coding scheme procedures<p>The coding scheme procedures domain included items that assessed the methods used to systematically code the information within primary studies. Results for each item included in the domain are graphically presented in the lower right-hand panel of </p>
Coding scheme content<p>The content of the coding schemes used across the included reviews was also considered. Results for each item included in the domain are graphically presented in the upper right-hand panel of </p>
Figure 2.<p>Percentage of systematic review quality indicators marked as present and not for the search procedures, coding categories, and data analysis plan domains.</p>

Data analysis plan<p>The data analysis plan items related to whether the reviews contained information on the processes and procedures that were used to analyze the data, such as the particular statistical models in a meta-analysis, the process for identifying themes and patterns within metasyntheses, or the use of descriptive statistics in cases where synthesis was not the goal of the review. Results for each item included in the domain are graphically presented in the lower right-hand panel of </p>
Discussion<p>The purpose of this article was to provide an overview and rationale for rigorous systematic review methods to ensure that the information drawn from these reviews is the most valid and current available. To examine the extent to which systematic reviews published in </p>
Quality Indicator Application<p>The application of the review indicators led to the identification of several areas of strength across the included reviews. For instance, there were a number of specific methodological criteria that were present across all of the reviews. Examples include the specification of inclusion criteria, noting the particular special educational label necessary for inclusion, and providing information on the total number of studies in the review. The methodological domain with the greatest adherence across the reviews was the application of inclusion and exclusion criteria. As such, it appears that systematic review authors have effectively established the boundaries of the review for their intended audiences. In fact, many of the criteria that were consistently implemented across the reviews reflected procedural components that could be replicated by other researchers. As others have pointed out (</p>
<p>The consistent adherence on the part of reviewers in providing detailed descriptions of the review procedures is certainly encouraging. Of course, there were some procedural areas where more consistent reporting is needed, such as describing the process for training coders on the coding scheme, providing details on the process for resolving coding disagreements, and addressing the methodological quality of the included studies. An examination of the quality indicators that were not consistently implemented reveals that many are related to the need to better report the results of the procedural indicators. For instance, the majority of the studies did not provide information on the reliability of the screening process, the total number of citations returned in the electronic search, and the number of total studies screened out during the search process. Rather than relate to issues of the reproducibility of the procedures, these indicators relate more to issues of transparency of the review. Research transparency is a multidimensional construct and is central to developing and disseminating empirically based information (</p>
Concluding Remarks<p>The dissemination of rigorous research designed to address the complex and varied needs of students with EBD is an essential mission of </p>
<p>It is instructive to consider some of the challenges associated with conducting a rigorous systematic review. Among the primary challenges in our discipline is the tendency of systematic reviewers to generalize the results too broadly and to assume that the results apply to all students with EBD. It is our observation that researchers conducting a systematic review will often not describe the conceptual reasons a particular intervention or program is expected to work and for whom (</p>
<p>It is also important to discuss some of the challenges of applying quality indicators to bodies of research. To be sure, assessing methodological quality is an important endeavor and one that is necessary to accurately contextualize research reports (</p>
Declaration of Conflicting Interests<p>The author(s) declared no potential conflicts of interest with respect to the research, authorship, and/or publication of this article.</p>
Funding<p>The author(s) received no financial support for the research, authorship, and/or publication of this article.</p>
References
American Psychological Association. (2010). Meta-analysis reporting standards. Washington, DC: Author.
Baumeister R. F., Leary M. R. (1997). Writing a narrative literature review. Review of General Psychology, 1, 311–320.
Borenstein M., Hedges L. V., Higgins J. P. T., Rothstein H. R. (2009). Introduction to meta-analysis. New York, NY: John Wiley.
Bruhn A., McDaniel S., Kreigh C. (2015). Self-monitoring interventions for students with behavior problems: A systematic review of current research. Behavioral Disorders, 40, 102–121.
Collier-Meek M. A., Fallon L. M., Sanetti L. M. H., Maggin D. M. (2013). Focus on implementation: Assessing and promoting treatment fidelity. Teaching Exceptional Children, 45, 52–59.
Cook B. G. (2014). A call for examining replication and bias in special education research. Remedial and Special Education, 35, 233–246. doi:10.1177/0741932514528995
Cook B. G., Buysse V., Klingner J., Landrum T., McWilliam R., Tankersley M., Test D. (2014). Council for Exceptional Children: Standards for evidence-based practices in special education. Teaching Exceptional Children, 46, 206–212. doi:10.1177/0040059914531389
Cook B. G., Tankersley M., Landrum T. J. (2009). Determining evidence-based practices in special education. Exceptional Children, 75, 365–383. doi:10.1177/001440290907500306
Cooper H., Hedges L. V., Valentine J. C. (2009). The handbook of research synthesis and meta-analysis (2nd ed., pp. 3–16). New York, NY: Russell Sage Foundation.
Cordray D. S., Morphy P. (2009). Research synthesis and public policy. In Cooper H., Hedges L. V., Valentine J. C. (Eds.), The handbook of research synthesis and meta-analysis (2nd ed., pp. 473–493). New York, NY: Russell Sage Foundation.
Gage N., Gersten R., Sugai G., Newman-Gonchar R. (2013). Disproportionality of English learners with emotional and/or behavioral disorders: A comparative meta-analysis with English learners with learning disabilities. Behavioral Disorders, 38, 123–136.
Gersten R., Fuchs L. S., Compton D., Coyne M., Greenwood C., Innocenti M. S. (2005). Quality indicators for group experimental and quasi-experimental research in special education. Exceptional Children, 71, 149–164.
Gough D., Oliver S., Thomas J. (2013). Learning from research: Systematic reviews for informing policy decisions: A quick guide. London, England: Alliance for Useful Evidence.
Higgins J. P., Green S. (Eds.). (2011). Cochrane handbook for systematic reviews of interventions (Vol. 5.1). Chichester, UK: Wiley-Blackwell.
Knowles C., Meng P., Machalicek W. (2015). Task sequencing for students with emotional and behavioral disorders: A systematic review. Behavior Modification, 39, 136–166.
Lipsey M. W., Wilson D. B. (2001). Practical meta-analysis. Thousand Oaks, CA: SAGE.
Maggin D. M. (2015). Considering generality in the systematic review and meta-analysis of single-case research: A response to Hitchcock et al. Journal of Behavioral Education, 24, 470–482.
Maggin D. M., Chafouleas S. M. (2013). Introduction to the special series issues and advances of synthesizing single-case research. Remedial and Special Education, 34, 3–8.
Maggin D. M., Wehby J. H., Farmer T. W., Brooks D. S. (2016). Intensive interventions for students with emotional and behavioral disorders: Issues, theory, and future Directions. Journal of Emotional and Behavioral Disorders, 24, 127–137.
Maggin D. M., Zurheide J., Pickett K. C., Baillie S. J. (2015). A systematic evidence review of the check-in/check-out program for reducing student challenging behaviors. Journal of Positive Behavior Interventions, 17, 197–208.
Maggin D. M., Johnson A. H., Chafouleas S. M., Ruberto L. M., Berggren M. (2012). A systematic evidence review of school-based group contingency interventions for students with challenging behavior. Journal of School Psychology, 50, 625–654.
Moher D., Shamseer L., Clarke M., Ghersi D., Liberati A., Petticrew M., Stewart L. A. (2015). Preferred reporting items for systematic review and meta-analysis protocols (PRISMA-P) 2015 statement. Systematic Reviews, 4, Article 1.
Odom S. L., Brantlinger E., Gersten R., Horner R. H., Thompson B., Harris K. R. (2005). Research in special education: Scientific methods and evidence-based practices. Exceptional Children, 71, 137–148.
Shavelson R. J., Towne L. (Eds.). (2002). Scientific research in education. Washington, DC: National Academies Press.
Talbott E., Maggin D. M., Van Acker E. Y., Kumm S. (in press). Quality indicators for reviews of research in special education. Exceptionality.
Travers J. C., Cook B. G., Therrien W. J., Coyne M. C. (2016). Replication in research in special education. Remedial and Special Education, 27, 195–204.
Valentine J. C. (2009). Judging the quality of primary research. In Cooper H., Hedges L. V., Valentine J. C. (Eds.), The handbook of research synthesis and meta-analysis (2nd ed., pp. 129–146). New York: Russell Sage Foundation.
What Works Clearinghouse. (2013). Procedures and standards handbook (Version 3.0). Retrieved from https://ies.ed.gov/ncee/wwc/Docs/referenceresources/wwc_procedures_v3_0_standards_handbook.pdf